{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    URL_ID                                                URL\n",
       "0       37  https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1       38  https://insights.blackcoffer.com/what-if-the-c...\n",
       "2       39  https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3       40  https://insights.blackcoffer.com/will-machine-...\n",
       "4       41  https://insights.blackcoffer.com/will-ai-repla...\n",
       "..     ...                                                ...\n",
       "109    146  https://insights.blackcoffer.com/blockchain-fo...\n",
       "110    147  https://insights.blackcoffer.com/the-future-of...\n",
       "111    148  https://insights.blackcoffer.com/big-data-anal...\n",
       "112    149  https://insights.blackcoffer.com/business-anal...\n",
       "113    150  https://insights.blackcoffer.com/challenges-an...\n",
       "\n",
       "[114 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = pd.read_csv(r\"E:\\Interview\\20211030 black_coffer\\Input.csv\")\n",
    "input_file = input_file.dropna()\n",
    "input_file['URL_ID'] =input_file['URL_ID'].astype(int)\n",
    "input_file['URL_ID'] =input_file['URL_ID'].astype(str)\n",
    "input_file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = input_file[\"URL\"][0]\n",
    "def data_extraction(filename, url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"\n",
    "    }\n",
    "    reqs = requests.get(url, headers= headers)\n",
    "    soup  = BeautifulSoup(reqs.text,'html.parser')\n",
    "    title = soup.title.string\n",
    "    p_tags = soup.find_all(\"p\")\n",
    "    text = \"\"\n",
    "    for i in p_tags:\n",
    "        text += i.get_text()\n",
    "    article = title +\"\\n\"+ text\n",
    "    filename = \"text_files/\"+filename + \".txt\"\n",
    "    with open(filename,\"w\", encoding = \"utf-8\") as file:\n",
    "        file.write(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in input_file.iterrows():\n",
    "    name = row[\"URL_ID\"]\n",
    "    url = row[\"URL\"]\n",
    "    data_extraction(name,url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = pd.DataFrame()\n",
    "output_file = output_file.append(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    URL_ID                                                URL\n",
       "0       37  https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1       38  https://insights.blackcoffer.com/what-if-the-c...\n",
       "2       39  https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3       40  https://insights.blackcoffer.com/will-machine-...\n",
       "4       41  https://insights.blackcoffer.com/will-ai-repla...\n",
       "..     ...                                                ...\n",
       "109    146  https://insights.blackcoffer.com/blockchain-fo...\n",
       "110    147  https://insights.blackcoffer.com/the-future-of...\n",
       "111    148  https://insights.blackcoffer.com/big-data-anal...\n",
       "112    149  https://insights.blackcoffer.com/business-anal...\n",
       "113    150  https://insights.blackcoffer.com/challenges-an...\n",
       "\n",
       "[114 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trash_remover(list):\n",
    "    \"\"\"\n",
    "    returns list elements without additional information\n",
    "    after the typographical symbol pipe (|)\n",
    "    and transform list in lower case\n",
    "    \"\"\"\n",
    "    for i in range(len(list)):\n",
    "        list[i] = list[i].lower()\n",
    "        for j in range(len(list[i])):\n",
    "            if list[i][j] == \"|\":\n",
    "                list[i] = list[i][:j].strip()\n",
    "                break\n",
    "    return list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making an empty list to store all stopwords\n",
    "stopwords = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('StopWords\\StopWords_Auditor.txt','r',encoding = 'utf-8') as file:\n",
    "    auditor_sw = file.read()\n",
    "    auditor_sw = auditor_sw.split('\\n')\n",
    "    auditor_sw = trash_remover(auditor_sw)\n",
    "for i in auditor_sw:\n",
    "    stopwords.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('StopWords\\StopWords_Currencies.txt','r',encoding = 'utf-8') as file:\n",
    "    currencies_sw = file.read()\n",
    "    currencies_sw = currencies_sw.split('\\n')\n",
    "    currencies_sw = trash_remover(currencies_sw)\n",
    "for i in currencies_sw:\n",
    "    stopwords.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('StopWords\\StopWords_DatesandNumbers.txt','r',encoding = 'utf-8') as file:\n",
    "    datesnum_sw = file.read()\n",
    "    datesnum_sw = datesnum_sw.split('\\n')\n",
    "    datesnum_sw = trash_remover(datesnum_sw)\n",
    "for i in datesnum_sw:\n",
    "    stopwords.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('StopWords\\StopWords_Generic.txt','r',encoding = 'utf-8') as file:\n",
    "    generic_sw = file.read()\n",
    "    generic_sw = generic_sw.split('\\n')\n",
    "    generic_sw = trash_remover(generic_sw)\n",
    "for i in generic_sw:\n",
    "    stopwords.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('StopWords\\StopWords_GenericLong.txt','r',encoding = 'utf-8') as file:\n",
    "    genericlong_sw = file.read()\n",
    "    genericlong_sw = genericlong_sw.split('\\n')\n",
    "    genericlong_sw = trash_remover(genericlong_sw)\n",
    "for i in genericlong_sw:\n",
    "    stopwords.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('StopWords\\StopWords_Geographic.txt','r',encoding = 'utf-8') as file:\n",
    "    geographic_sw = file.read()\n",
    "    geographic_sw = geographic_sw.split('\\n')\n",
    "    geographic_sw = trash_remover(geographic_sw)\n",
    "for i in geographic_sw:\n",
    "    stopwords.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('StopWords\\StopWords_Names.txt','r',encoding = 'utf-8') as file:\n",
    "    names_sw = file.read()\n",
    "    names_sw = names_sw.split('\\n')\n",
    "    names_sw = trash_remover(names_sw)\n",
    "for i in names_sw:\n",
    "    stopwords.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14109"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text_file,stop_words,output_file):\n",
    "    with open(text_file,'r') as file:\n",
    "        text = file.read()\n",
    "    words = text.split()\n",
    "\n",
    "    # creating empty list for filtered words\n",
    "    filter_words = []\n",
    "\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            filter_words.append(word)\n",
    "\n",
    "    filtered_text = \" \".join(filter_words)\n",
    "\n",
    "    with open(output_file, \"w\") as file:\n",
    "        file.write(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(37,151):\n",
    "    text_file = f\"text_files\\{i}.txt\"\n",
    "    filtered_file = f\"filtered_text_files\\{i}.txt\" \n",
    "    remove_stopwords(text_file,stopwords,filtered_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"MasterDictionary\\positive-words.txt\",'r') as file:\n",
    "    text = file.read()\n",
    "positive_words = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_score(text_file,positive_dict):\n",
    "    with open(text_file,'r', encoding = 'utf-8') as file:\n",
    "        text = file.read()\n",
    "    words = text.split()\n",
    "    positive_score = 0\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word in positive_dict:\n",
    "            positive_score += 1 \n",
    "    return positive_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_filenames = [f\"filtered_text_files\\{i}.txt\" for i in range(37,151)]\n",
    "positive_scores = []\n",
    "for filename in filter_filenames:\n",
    "    score = positive_score(filename, positive_words)\n",
    "    positive_scores.append(score)\n",
    "# print(positive_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file[\"POSITIVE SCORE\"] = positive_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"MasterDictionary\\negative-words.txt\",'r', encoding = \"utf-8\") as file:\n",
    "    text = file.read()\n",
    "negative_words = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_score(text_file,negative_dict):\n",
    "    with open(text_file,'r',encoding= 'utf-8') as file:\n",
    "        text = file.read()\n",
    "    words = text.split()\n",
    "    negative_score = 0\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word in negative_dict:\n",
    "            negative_score -= 1\n",
    "\n",
    "    return negative_score * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_score = []\n",
    "for filename in filter_filenames:\n",
    "    score = positive_score(filename, negative_words)\n",
    "    negative_score.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file[\"NEGATIVE SCORE\"] = negative_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_score(positive_score, negative_score):\n",
    "    polarity_score = (positive_score - negative_score)/ ((positive_score + negative_score) + 0.000001)\n",
    "    return polarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3827160446578266\n"
     ]
    }
   ],
   "source": [
    "print(polarity_score(output_file[\"POSITIVE SCORE\"][0], output_file[\"NEGATIVE SCORE\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_scores = list(output_file[\"POSITIVE SCORE\"])\n",
    "negative_scores = list(output_file[\"NEGATIVE SCORE\"])\n",
    "\n",
    "polarity_scores = []\n",
    "for i in range(114):\n",
    "    score = polarity_score(positive_scores[i], negative_scores[i])\n",
    "    polarity_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file[\"POLARITY SCORE\"] = polarity_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subjectivity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity_score(text_file,positive_score, negative_score):\n",
    "    with open(text_file,'r', encoding = 'utf-8') as file:\n",
    "        text = file.read()\n",
    "    words = text.split()\n",
    "    total_words = len(words)\n",
    "    subjectivity_score = (positive_score + negative_score)/ ((total_words) + 0.000001)\n",
    "    return subjectivity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectivity_scores = []\n",
    "for i in range(len(filter_filenames)):\n",
    "    score = subjectivity_score(filter_filenames[i], positive_scores[i], negative_scores[i])\n",
    "    subjectivity_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file[\"SUBJECTIVITY SCORE\"] = subjectivity_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Sentence Length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sentences(text):\n",
    "    sentences = text.split(\".\")\n",
    "    return len(sentences)\n",
    "\n",
    "def count_words(text):\n",
    "    words = text.split()\n",
    "    return len(words)\n",
    "\n",
    "def avg_sentence_length(text_file):\n",
    "    with open(text_file,'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    no_of_words = count_words(text)\n",
    "    no_of_sentences = count_sentences(text)\n",
    "    avg_sentence_length = no_of_words / no_of_sentences\n",
    "    return round(avg_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_filenames = [f\"text_files\\{i}.txt\" for i in range(37,151)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sen_lengths = []\n",
    "for filename in text_filenames:\n",
    "    length = avg_sentence_length(filename)\n",
    "    avg_sen_lengths.append(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file[\"AVG SENTENCE LENGTH\"] = avg_sen_lengths"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage of complex words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(word):\n",
    "    return len(\n",
    "        re.findall('(?!e$)[aeiou]+', word, re.I) +\n",
    "        re.findall('(?!es$)(?!ed$)[aeiou]', word, re.I) \n",
    "    )\n",
    "    # (?!e$)[aeiou]+ pattern means to find vowel a,e,i,o,u in the word without the ending letter 'e'\n",
    "    # (?!es$)(?!ed$)[aeiou] pattern is for handling the exception of 'es' and 'ed' ending words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_complex_words(filename):\n",
    "    with open(filename,'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    words = text.split()\n",
    "    complex_words = 0\n",
    "    for word in words:\n",
    "        if (count_syllables(word) > 2):\n",
    "            complex_words += 1\n",
    "    return complex_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_of_complex_words(filename):\n",
    "    with open(filename,'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    no_of_words = count_words(text)\n",
    "    no_of_complex_words = count_complex_words(filename)\n",
    "    percent = round((no_of_complex_words / no_of_words)* 100, 3)\n",
    "    \n",
    "    return percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_of_complex_words = []\n",
    "for filename in text_filenames:\n",
    "    percent = percent_of_complex_words(filename)\n",
    "    p_of_complex_words.append(percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file[\"PERCENTAGE OF COMPLEX WORDS\"] = p_of_complex_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fog Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fog_index(average_sentence_len, percent_of_complex_words):\n",
    "    fog_index = round(0.4*(average_sentence_len + percent_of_complex_words), 3)\n",
    "    return fog_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "fog_indexes = []\n",
    "for i in range(114):\n",
    "    index = fog_index(output_file[\"AVG SENTENCE LENGTH\"][i], output_file[\"PERCENTAGE OF COMPLEX WORDS\"][i])\n",
    "    fog_indexes.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file[\"FOG INDEX\"] = fog_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>56</td>\n",
       "      <td>25</td>\n",
       "      <td>0.382716</td>\n",
       "      <td>0.078337</td>\n",
       "      <td>23</td>\n",
       "      <td>60.798</td>\n",
       "      <td>33.519</td>\n",
       "      <td>23</td>\n",
       "      <td>1067</td>\n",
       "      <td>1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>45</td>\n",
       "      <td>28</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.108148</td>\n",
       "      <td>20</td>\n",
       "      <td>49.536</td>\n",
       "      <td>27.814</td>\n",
       "      <td>20</td>\n",
       "      <td>694</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>57</td>\n",
       "      <td>32</td>\n",
       "      <td>0.280899</td>\n",
       "      <td>0.099330</td>\n",
       "      <td>20</td>\n",
       "      <td>57.049</td>\n",
       "      <td>30.820</td>\n",
       "      <td>20</td>\n",
       "      <td>955</td>\n",
       "      <td>977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>42</td>\n",
       "      <td>14</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.075984</td>\n",
       "      <td>19</td>\n",
       "      <td>52.190</td>\n",
       "      <td>28.476</td>\n",
       "      <td>19</td>\n",
       "      <td>822</td>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>48</td>\n",
       "      <td>18</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.076834</td>\n",
       "      <td>21</td>\n",
       "      <td>51.571</td>\n",
       "      <td>29.028</td>\n",
       "      <td>21</td>\n",
       "      <td>870</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.047619</td>\n",
       "      <td>0.088983</td>\n",
       "      <td>16</td>\n",
       "      <td>54.835</td>\n",
       "      <td>28.334</td>\n",
       "      <td>16</td>\n",
       "      <td>482</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.057292</td>\n",
       "      <td>20</td>\n",
       "      <td>54.220</td>\n",
       "      <td>29.688</td>\n",
       "      <td>20</td>\n",
       "      <td>591</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>25</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.152542</td>\n",
       "      <td>0.094551</td>\n",
       "      <td>15</td>\n",
       "      <td>51.733</td>\n",
       "      <td>26.693</td>\n",
       "      <td>15</td>\n",
       "      <td>582</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.083056</td>\n",
       "      <td>21</td>\n",
       "      <td>55.735</td>\n",
       "      <td>30.694</td>\n",
       "      <td>21</td>\n",
       "      <td>311</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>0.120594</td>\n",
       "      <td>16</td>\n",
       "      <td>51.495</td>\n",
       "      <td>26.998</td>\n",
       "      <td>16</td>\n",
       "      <td>534</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0       37  https://insights.blackcoffer.com/ai-in-healthc...              56   \n",
       "1       38  https://insights.blackcoffer.com/what-if-the-c...              45   \n",
       "2       39  https://insights.blackcoffer.com/what-jobs-wil...              57   \n",
       "3       40  https://insights.blackcoffer.com/will-machine-...              42   \n",
       "4       41  https://insights.blackcoffer.com/will-ai-repla...              48   \n",
       "..     ...                                                ...             ...   \n",
       "109    146  https://insights.blackcoffer.com/blockchain-fo...              20   \n",
       "110    147  https://insights.blackcoffer.com/the-future-of...              26   \n",
       "111    148  https://insights.blackcoffer.com/big-data-anal...              25   \n",
       "112    149  https://insights.blackcoffer.com/business-anal...              23   \n",
       "113    150  https://insights.blackcoffer.com/challenges-an...              30   \n",
       "\n",
       "     NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0                25        0.382716            0.078337                   23   \n",
       "1                28        0.232877            0.108148                   20   \n",
       "2                32        0.280899            0.099330                   20   \n",
       "3                14        0.500000            0.075984                   19   \n",
       "4                18        0.454545            0.076834                   21   \n",
       "..              ...             ...                 ...                  ...   \n",
       "109              22       -0.047619            0.088983                   16   \n",
       "110               7        0.575758            0.057292                   20   \n",
       "111              34       -0.152542            0.094551                   15   \n",
       "112               2        0.840000            0.083056                   21   \n",
       "113              35       -0.076923            0.120594                   16   \n",
       "\n",
       "     PERCENTAGE OF COMPLEX WORDS  FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                         60.798     33.519                                23   \n",
       "1                         49.536     27.814                                20   \n",
       "2                         57.049     30.820                                20   \n",
       "3                         52.190     28.476                                19   \n",
       "4                         51.571     29.028                                21   \n",
       "..                           ...        ...                               ...   \n",
       "109                       54.835     28.334                                16   \n",
       "110                       54.220     29.688                                20   \n",
       "111                       51.733     26.693                                15   \n",
       "112                       55.735     30.694                                21   \n",
       "113                       51.495     26.998                                16   \n",
       "\n",
       "     COMPLEX WORD COUNT  WORD COUNT  \n",
       "0                  1067        1112  \n",
       "1                   694         740  \n",
       "2                   955         977  \n",
       "3                   822         849  \n",
       "4                   870         916  \n",
       "..                  ...         ...  \n",
       "109                 482         513  \n",
       "110                 591         617  \n",
       "111                 582         653  \n",
       "112                 311         319  \n",
       "113                 534         584  \n",
       "\n",
       "[114 rows x 12 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Number of Words Per Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word_per_sentence(filename):\n",
    "    with open(filename,'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    no_of_words = count_words(text)\n",
    "    no_of_sentences = count_sentences(text)\n",
    "    average = round(no_of_words / no_of_sentences)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_word_per_sentences = []\n",
    "for filename in text_filenames:\n",
    "    average = avg_word_per_sentence(filename)\n",
    "    avg_word_per_sentences.append(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file[\"AVG NUMBER OF WORDS PER SENTENCE\"] = avg_word_per_sentences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_complex_words = []\n",
    "for filename in text_filenames:\n",
    "    count = count_complex_words(filename)\n",
    "    no_of_complex_words.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file[\"COMPLEX WORD COUNT\"] = no_of_complex_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing stopwords using nltk package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_count(text_file):\n",
    "    \"\"\"removing stopwords using nltk package\"\"\"\n",
    "    with open(text_file,'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    stop_words = list(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    wordcount = len(words)\n",
    "    return wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_count(r\"text_files/37.txt\")\n",
    "word_count = []\n",
    "for filename in text_filenames:\n",
    "    count = get_word_count(filename)\n",
    "    word_count.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file[\"WORD COUNT\"] = word_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syllable Per word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_per_word(filename):\n",
    "    \"\"\" Returns average syllable per word\"\"\"\n",
    "    with open(filename,'r', encoding = 'utf-8') as file:\n",
    "        text = file.read()\n",
    "    words = text.split()\n",
    "    counts = []\n",
    "    for word in words:\n",
    "        counts.append(count_syllables(word))\n",
    "    syllable_per_word = round(sum(counts)/ len(counts))\n",
    "\n",
    "    return syllable_per_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable_per_word_count = []\n",
    "for filename in text_filenames:\n",
    "    syllable_per_word_count.append(syllable_per_word(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file[\"SYLLABLE PER WORD\"] = syllable_per_word_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pronoun(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    pattern = r\"\\b(I|we|my|ours|us)\\b\" \n",
    "    matches = len(re.findall(pattern, text))\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronoun_count = []\n",
    "for filename in text_filenames:\n",
    "    pronoun_count.append(count_pronoun(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file[\"PERSONAL PRONOUNS\"] = pronoun_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_characters(filename):\n",
    "    with open(filename, 'r', encoding = 'utf-8') as file:\n",
    "        text = file.read()\n",
    "    text = text.replace(\" \", \"\")\n",
    "    \n",
    "    return len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word_length(filename):\n",
    "    with open(filename, 'r',encoding= 'utf-8') as file:\n",
    "        text = file.read()\n",
    "    num_of_char = count_characters(filename)\n",
    "    num_of_words = count_words(text)\n",
    "\n",
    "    return int(num_of_char/num_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_length_count = []\n",
    "for filename in text_filenames:\n",
    "    word_length_count.append(avg_word_length(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file[\"AVG WORD LENGTH\"] = word_length_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving into CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file.to_csv(\"Output.csv\", index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7679c2132d3f6ce38c9df14d554b39c06862b36a4e6689c81f9ae15bd0911d7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
